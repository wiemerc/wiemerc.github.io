<!DOCTYPE html>
<html lang="en">
<head>

        <meta name="google-site-verification" content="pGw_A7NkX3r_PZULCdMzWHWiOWWIqLUk2Ckj0VjIJ1I" />
        <meta charset="utf-8" />
        <title>Packet, Where Are You: DNS Service Discovery for Kerberos Failed Because of Wrong MTU Size in Kubernetes Cluster</title>
        <link rel="stylesheet" href="https://wiemerc.github.io/theme/css/main.css" />

        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://wiemerc.github.io/">Constantin Wiemer's Blog  <strong><p>A blog about my programming projects, computer security and systems programming</strong></a></h1>
                <nav><ul>
    
                        <li><a href="https://wiemerc.github.io/pages/about-me.html">About me</a></li>
                    <li><a href="https://wiemerc.github.io/category/computer-history.html">Computer History</a></li>
                    <li><a href="https://wiemerc.github.io/category/computer-security.html">Computer Security</a></li>
                    <li class="active"><a href="https://wiemerc.github.io/category/debugging.html">Debugging</a></li>
                    <li><a href="https://wiemerc.github.io/category/programming-projects.html">Programming Projects</a></li>
                </ul>
                </nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="https://wiemerc.github.io/packet-where-are-you-dns-service-discovery-for-kerberos-failed-because-of-wrong-mtu-size-in-kubernetes-cluster.html" rel="bookmark"
           title="Permalink to Packet, Where Are You: DNS Service Discovery for Kerberos Failed Because of Wrong MTU Size in Kubernetes Cluster">Packet, Where Are You: DNS Service Discovery for Kerberos Failed Because of Wrong MTU Size in Kubernetes Cluster</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <span>Tue 03 October 2023</span>

</footer><!-- /.post-info -->      <div class="sect1">
<h2 id="_the_problem">The problem</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Recently I had a very tricky network problem at work that involved Kerberos, DNS and Kubernetes. This article is a writeup of the analysis and the measures we took to solve the issue.</p>
</div>
<div class="paragraph">
<p>In my team at work we&#8217;re running most of our applications in Kubernetes clusters on AWS (the EKS service). One of our applications uses Kerberos authentication against our corporate Active Directory. As we didn&#8217;t want to statically configure any KDCs (<a href="https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-2000-server/cc961976(v=technet.10)?redirectedfrom=MSDN#key-distribution"><em>Key Distribution Center</em></a>, basically a part of the Kerberos server) for the <a href="https://web.mit.edu/kerberos/kfw-4.1/kfw-4.1/kfw-4.1-help/html/kerberos_terminology.htm">realms</a>, Kerberos uses <a href="https://datatracker.ietf.org/doc/html/rfc6763"><em>DNS service discovery</em></a> to find the KDCs. This means it uses the service name <code>_kerberos._tcp.REALM.EXAMPLE.COM</code> to dynamically get a list of KDCs for a specific realm from the DNS server(s).</p>
</div>
<div class="paragraph">
<p>The problem first manifested itself in our application being unable to access a certain web service that is protected by Kerberos authentication. The error message (returned by the <a href="https://datatracker.ietf.org/doc/html/rfc2743"><em>GSSAPI</em></a> that our application uses) was "Cannot find KDC for requested realm". This hinted at a problem with the DNS service discovery described before. However, the application could access other web services that also use Kerberos for authentication, so Kerberos and DNS seemed to work in general. But then we remembered that our company uses two Kerberos realms (for whatever reason) and we saw that the failing web service belonged to one realm while the working ones belonged to the other. To confirm that DNS service discovery was indeed the problem, we ran <code>dig</code> commands like <code>dig +noall +answer SRV _kerberos._tcp.REALM.EXAMPLE.COM</code> in a container in the Kubernetes cluster for both realms, and as we had expected, <code>dig</code> could resolve one realm but not the other. We first suspected of course that there might by a problem on the server side, that is with the Active Directory or the DNS server. But then we ran the same <code>dig</code> commands on a machine outside of the cluster and, to our surprise, <code>dig</code> could resolve both realms. This meant that the problem had to be somehow related to Kubernetes, but left us quite puzzled.</p>
</div>
<div class="paragraph">
<p>To get an idea what was really going on, I ran <code>tcpdump</code> on the cluster nodes. This showed three interesting things, which can be seen in the screenshot below. <sup class="footnote">[<a id="_footnoteref_1" class="footnote" href="#_footnotedef_1" title="View footnote.">1</a>]</sup></p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://wiemerc.github.io/images/dns-sd/network-trace-dns-server.png" alt="Network trace showing the DNS request and answer and the ICMP message" width="1100" height="655">
</div>
<div class="title">Figure 1. Network trace showing the DNS request and answer and the ICMP <em>Destination Unreachable (Fragmentation needed)</em> message (Cluster node = 10.1.79.36, DNS server 10.1.70.201, pod = 192.168.168.115)</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The DNS server uses UDP (and not TCP) and its answers are each sent in one UDP datagram and therefore also in one IP packet. These IP packets have the <em>Don&#8217;t fragment</em> flag set.</p>
</li>
<li>
<p>The size of the answer to the query for the second realm (2318 octets) exceeds the MTU size that was configured on all network interfaces in the cluster (1500 octets, the typical size for Ethernet).</p>
</li>
<li>
<p>ICMP <em>Destination Unreachable (Fragmentation needed)</em> messages are sent from the cluster nodes to the DNS server.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_solution">The solution</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So it seemed pretty clear what the root cause of the problem was and how we could fix it: We just needed to increase the MTU size of the network interfaces in the cluster. But how do you do that? There is a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a> <em>aws-node</em> running on each EKS cluster that is part of the <a href="https://aws.github.io/aws-eks-best-practices/networking/vpc-cni/">AWS VPC CNI</a>. It&#8217;s responsible for managing the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html"><em>Elastic Network Interfaces</em></a> (ENI) on the cluster nodes and for assigning IP addresses to pods. As it turns out, this DaemonSet has an environment variable <em>AWS_VPC_ENI_MTU</em> to configure the MTU size to use for the ENIs. So it seemed we could just set this variable to a higher value, like 9001 octets (the default value for Ethernet jumbo frames). And this is what we ended up doing eventually. But as the clusters are managed by another group in our company, it took us a while to get this variable changed permanently. Therefore we had to implement a workaround first.</p>
</div>
<div class="paragraph">
<p>For this workaround one of my colleagues was really helpful. He pointed out that we wouldn&#8217;t run into the problem if we used TCP instead of UDP for the DNS service discovery (as the network stack of the OS partitions the data to be sent into TCP segments that each fit into one IP packet, so the DNS server&#8217;s answer that was larger than the MTU of the network interface would be split into two TCP segments). I hadn&#8217;t thought of this before but when I tried it using <code>dig</code> 's <code>+tcp</code> option it of course worked. Unfortunately for use, we couldn&#8217;t force the Kerberos client (or the resolver of the OS or <em>CoreDNS</em> or any other component that is involved in DNS) to use TCP. <sup class="footnote">[<a id="_footnoteref_2" class="footnote" href="#_footnotedef_2" title="View footnote.">2</a>]</sup>. But then my colleague had another good idea: Could we run <code>dig</code> with the <code>+tcp</code> option somewhere in the cluster periodically to resolve the second realm, so that the answer would already be in the cache when the Kerberos client comes along and tries to resolve it? We tried it out and it actually worked, <sup class="footnote">[<a id="_footnoteref_3" class="footnote" href="#_footnotedef_3" title="View footnote.">3</a>]</sup> so we implemented it with a sidecar container in our application&#8217;s pod.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_a_more_detailed_analysis">A more detailed analysis</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Although we had a workaround and a final solution, I was still not completely satisfied. I wondered which Kubernetes component was actually dropping the DNS server&#8217;s answers and sending the ICMP messages and soon realized that I had no idea how the networking in Kubernetes actually works. Luckily I found an excellent <a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/">guide</a> on the internet. Through this guide I learned that Kubernetes uses standard network components of the Linux kernel like physical interfaces, <a href="https://man7.org/linux/man-pages/man4/veth.4.html">virtual Ethernet devices</a>  (e. g. the ENIs mentioned above) and <a href="https://wiki.archlinux.org/title/network_bridge">bridges</a>. So it seemed to me that the kernel itself had to be responsible for the things we had observed.</p>
</div>
<div class="paragraph">
<p>Then I thought it would be really cool to actually be able to see the path an IP packet, in this case the DNS server&#8217;s answer, takes through the Linux kernel, from the network interface it arrives at to the process that, well, processes it. And lo and behold, after some googling I found that a tool exists to do that: <code>pwru</code>, which stands for <a href="https://github.com/cilium/pwru"><em>Packet, where are you?</em></a>. What it does is it uses <a href="https://en.wikipedia.org/wiki/EBPF"><em>eBPF</em></a> to instrument the kernel&#8217;s network stack and traces the way a certain packet (matching criteria like IP address, source / destination port and so on) takes through the kernel. The output you get is a list of kernel functions that were called when this packet was processed. Of course, to really make sense of the output, you should be at least somewhat familiar with the internals of the kernel&#8217;s network stack. I am certainly not, but I thought that maybe the names of the kernel functions would give a hint anyway, so I decided to give the tool a spin and try to analyze our problem with it.</p>
</div>
<div class="paragraph">
<p>I ran it twice on the cluster node that hosted the pod / container which I ran the <code>dig</code> command in and filtered out the packet that contained the DNS server&#8217;s answer. The first run was with an MTU size of 1500, so the packet was dropped. Then I increased the MTU size to 9001, which means that the packet made it back to <code>dig</code>. The two listings below show the (edited) output of <code>pwru</code> (the exact command was <code>pwru --all-kmods --output-meta 'udp and src port 9053'</code>).</p>
</div>
<div class="listingblock">
<div class="title">Listing 1. Output of <code>pwru</code> (edited), MTU = 1500 octets in the cluster</div>
<div class="content">
<pre>...
              ip_forward netns=4026531992 mark=0x0 ifindex=5 proto=8 mtu=1500 len=2379
             __icmp_send netns=4026531992 mark=0x0 ifindex=5 proto=8 mtu=1500 len=2379
...</pre>
</div>
</div>
<div class="listingblock">
<div class="title">Listing 2. Output of <code>pwru</code> (edited), MTU = 9001 octets in the cluster</div>
<div class="content">
<pre>...
              ip_forward netns=4026531992 mark=0x0 ifindex=3 proto=8 mtu=9001 len=2379
...
               ip_output netns=4026531992 mark=0x0 ifindex=3 proto=8 mtu=9001 len=2379
...
                netif_rx netns=4026533409 mark=0x0 ifindex=3 proto=8 mtu=9001 len=2379
...
                  ip_rcv netns=4026533409 mark=0x0 ifindex=3 proto=8 mtu=9001 len=2379
...
                 udp_rcv netns=4026533409 mark=0x0 ifindex=3 proto=8 mtu=9001 len=2359
...
         skb_consume_udp netns=0 mark=0x0 ifindex=0 proto=8 mtu=0 len=2351</pre>
</div>
</div>
<div class="paragraph">
<p>In both cases the trace started with the same 22 kernel functions, of which I show only the last in the listings, <code>ip_forward</code>. After this function the traces looked very different, so it seemed to me that it might be the one worth looking at in more detail. As I said before, I am by no means familiar with the network stack of Linux, but when I looked at the <a href="https://elixir.bootlin.com/linux/v6.5/source/net/ipv4/ip_forward.c#L86">source code</a> of this function I found that I could follow it quite easily nonetheless. In line <a href="https://elixir.bootlin.com/linux/v6.5/source/net/ipv4/ip_forward.c#L136">136</a> the size of the packet that is about to be forwarded is checked against the MTU of the route for this packet (the function <code>ip_exceeds_mtu</code>). If the packet is larger than the MTU the exact same ICMP message that I saw in the network trace (<em>Destination Unreachable (Fragmentation needed)</em>) is sent (by the function <code>icmp_send</code>) and the packet is dropped. So <code>pwru</code> helped me locate the source of our problem down to a single line in the kernel code, which I think is really cool :-) <sup class="footnote">[<a id="_footnoteref_4" class="footnote" href="#_footnotedef_4" title="View footnote.">4</a>]</sup></p>
</div>
<div class="paragraph">
<p>In the trace for the second case (MTU set to 9001 octets) <code>ip_forward</code> was followed by a lot more functions, of which in the listing I only show a few that I thought indicate that the packet was actually delivered to <code>dig</code>. But I didn&#8217;t investigate this case further, so I&#8217;m not going to go into any details here.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusion">Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Although I was annoyed at first because we had to debug just another problem with Kubernetes (my team is in the process of migrating some applications from dedicated servers to Kubernetes and this is not the first problem we had), in the end I really enjoyed it and of course learned a lot. First of all, this problem reminded me that issues at the application level can be caused by things deep down in the network. I think I&#8217;ve not even thought about MTU size in years, let alone configured it. I wouldn&#8217;t have imagined that such a low-level thing could cause Kerberos authentication to fail.</p>
</div>
<div class="paragraph">
<p>Then this problem was a good opportunity to learn more about Kubernetes networking which I had had basically not clue about before. Finally I added a new tool to my toolbox: <code>pwru</code>. I think it might be useful in the future, as I tend to be the guy at work who gets called when the network is causing trouble.</p>
</div>
<div class="paragraph">
<p>I hope you liked this article. Fee free to reach out to me if you have questions or comments.</p>
</div>
</div>
</div>
<div id="footnotes">
<hr>
<div class="footnote" id="_footnotedef_1">
<a href="#_footnoteref_1">1</a>. To tell the truth, the screenshot doesn&#8217;t show the network trace from one of the cluster nodes. Instead it&#8217;s a trace taken on a machine outside of the cluster, running a simple home-grown DNS server (that I already had written for another project, in Python using <a href="https://scapy.net/"><em>Scapy</em></a>), which I used to reproduce the problem more easily. For some reason unknown to me, on the cluster node I only saw the ICMP messages but not the DNS requests and answers.
</div>
<div class="footnote" id="_footnotedef_2">
<a href="#_footnoteref_2">2</a>. Actually, there might have been a way, but we didn&#8217;t pursue this option further.
</div>
<div class="footnote" id="_footnotedef_3">
<a href="#_footnoteref_3">3</a>. In reality it doesn&#8217;t work 100% of the time because there is a race condition. The cached answer (I assume it&#8217;s CoreDNS that does the caching but I haven&#8217;t really verified) has an associated TTL (30 seconds in our case) and it can happen that the Kerberos client tries to resolve the realm after the answer has expired in the cache but before the next periodic run of <code>dig</code> (every 10 seconds). But we deemed this solution good enough as a workaround.
</div>
<div class="footnote" id="_footnotedef_4">
<a href="#_footnoteref_4">4</a>. Of course this is not a bug in the kernel but a result of the packet being too big and / or the MTU size to small, but I think you know what I mean.
</div>
</div>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
            <p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. Powered by <a href="http://getpelican.com/">Pelican</a>. Theme <a href="https://github.com/blueicefield/pelican-blueidea/">blueidea</a>, inspired by the default theme.</p>
        </footer><!-- /#contentinfo -->

</body>
</html>